{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg_sentence_length  venue   \n",
      "0            24.723810      5  \\\n",
      "1            28.226257      4   \n",
      "2            14.513618      5   \n",
      "3            25.314816      5   \n",
      "4            25.141975      6   \n",
      "\n",
      "                                          token_mask  arxiv   \n",
      "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \\\n",
      "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0   \n",
      "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0   \n",
      "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0   \n",
      "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1   \n",
      "\n",
      "   abstract_contains_outperform  most_recent_reference_year   \n",
      "0                             0                           6  \\\n",
      "1                             0                           7   \n",
      "2                             0                           7   \n",
      "3                             0                           7   \n",
      "4                             0                           6   \n",
      "\n",
      "   title_contains_neural  num_authors  num_ref_to_sections   \n",
      "0                      0            4                    0  \\\n",
      "1                      0            2                   10   \n",
      "2                      0            1                    1   \n",
      "3                      0            1                    6   \n",
      "4                      0            1                    0   \n",
      "\n",
      "   avg_length_reference_mention_contexts  ...  many_split  contains_appendix   \n",
      "0                             288.333344  ...          49                  0  \\\n",
      "1                             346.227264  ...          97                  1   \n",
      "2                             213.250000  ...          53                  1   \n",
      "3                             287.052643  ...           5                  0   \n",
      "4                             357.571442  ...          33                  0   \n",
      "\n",
      "   abstract_contains_deep  abstract_contains_state-of-the-art  num_uniq_words   \n",
      "0                       0                                   0            1991  \\\n",
      "1                       0                                   0            2764   \n",
      "2                       0                                   0            1000   \n",
      "3                       0                                   0            1303   \n",
      "4                       0                                   0            1451   \n",
      "\n",
      "                                           token_ids  title_contains_gan   \n",
      "0  [101, 2057, 8970, 1037, 7705, 2005, 22910, 283...                   0  \\\n",
      "1  [101, 9420, 5398, 1997, 11702, 2006, 6550, 200...                   0   \n",
      "2  [101, 1999, 2023, 4087, 3189, 1045, 2265, 2008...                   0   \n",
      "3  [101, 2391, 8044, 2024, 4520, 1997, 2685, 1999...                   0   \n",
      "4  [101, 2087, 2783, 2773, 17547, 3001, 2191, 222...                   0   \n",
      "\n",
      "   num_recent_references  num_ref_to_equations  year  \n",
      "0                      0                     0  2007  \n",
      "1                      0                     6  2007  \n",
      "2                      0                     0  2007  \n",
      "3                      0                     0  2007  \n",
      "4                      0                     0  2008  \n",
      "\n",
      "[5 rows x 34 columns]\n",
      "Shape: (100, 34)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "def tfrecord_to_dataframe(tfrecord_path, max_records=None):\n",
    "    \"\"\"\n",
    "    Legge un file .tf_record e lo converte in un DataFrame pandas.\n",
    "    max_records = None -> legge tutto il file\n",
    "    \"\"\"\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    records = []\n",
    "\n",
    "    for i, raw_record in enumerate(dataset):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "        # Converti in dict\n",
    "        features = {}\n",
    "        for k, v in example.features.feature.items():\n",
    "            # int64\n",
    "            if v.int64_list.value:\n",
    "                features[k] = list(v.int64_list.value)\n",
    "                if len(features[k]) == 1:\n",
    "                    features[k] = features[k][0]  # scalar\n",
    "            # float\n",
    "            elif v.float_list.value:\n",
    "                features[k] = list(v.float_list.value)\n",
    "                if len(features[k]) == 1:\n",
    "                    features[k] = features[k][0]\n",
    "            # bytes (string)\n",
    "            elif v.bytes_list.value:\n",
    "                features[k] = [x.decode(\"utf-8\") for x in v.bytes_list.value]\n",
    "                if len(features[k]) == 1:\n",
    "                    features[k] = features[k][0]\n",
    "\n",
    "        records.append(features)\n",
    "\n",
    "        if max_records is not None and i + 1 >= max_records:\n",
    "            break\n",
    "\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "# === USO ===\n",
    "df = tfrecord_to_dataframe(\"../dat/PeerRead/proc/arxiv-all.tf_record\", max_records=100)\n",
    "\n",
    "print(df.head())\n",
    "print(\"Shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
